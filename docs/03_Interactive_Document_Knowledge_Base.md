# Interactive Document Knowledge Base (RAG) æŠ€è¡“æ–‡æª”

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

Interactive Document Knowledge Base æ˜¯ä¸€å€‹åŸºæ–¼æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG) æŠ€è¡“çš„æ™ºèƒ½æ–‡æª”å•ç­”ç³»çµ±ã€‚è©²ç³»çµ±å…è¨±ç”¨æˆ¶ä¸Šå‚³å¤šç¨®æ ¼å¼çš„æ–‡æª”ï¼Œå»ºç«‹æŒä¹…åŒ–çš„çŸ¥è­˜åº«ï¼Œä¸¦é€šéè‡ªç„¶èªè¨€æŸ¥è©¢ç²å¾—æº–ç¢ºã€æœ‰ä¾†æºå¼•ç”¨çš„ç­”æ¡ˆã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### ä¸»è¦ç‰¹æ€§
1. **å¤šæ–‡æª”å•ç­”**: åŸºæ–¼ä¸Šå‚³æ–‡æª”å…§å®¹çš„æ™ºèƒ½å•ç­”ç³»çµ±
2. **æ–‡æª”æ‘˜è¦ç”Ÿæˆ**: è‡ªå‹•ç”Ÿæˆå–®å€‹æ–‡æª”æˆ–æ•´å€‹çŸ¥è­˜åº«çš„æ‘˜è¦
3. **æ™ºèƒ½æ¸¬é©—ç”Ÿæˆ**: åŸºæ–¼æ–‡æª”å…§å®¹è‡ªå‹•å‰µå»ºå¤šé¸é¡Œæ¸¬é©—
4. **ä¾†æºå¼•ç”¨**: æ‰€æœ‰ç­”æ¡ˆéƒ½åŒ…å«å…·é«”çš„æ–‡æª”ä¾†æºå¼•ç”¨
5. **æŒä¹…åŒ–å­˜å„²**: ã€Œä¸Šå‚³ä¸€æ¬¡ï¼Œå¤šæ¬¡æŸ¥è©¢ã€çš„é«˜æ•ˆæ¶æ§‹

### æŠ€è¡“äº®é»
- **å®Œæ•´ RAG ç®¡é“**: å¾æ–‡æª”æ”å–åˆ°ç­”æ¡ˆç”Ÿæˆçš„ç«¯åˆ°ç«¯æµç¨‹
- **LangChain æ¡†æ¶**: ä½¿ç”¨ LangChain çš„æ¨™æº–åŒ–çµ„ä»¶å’Œéˆå¼æ“ä½œ
- **å‘é‡æ•¸æ“šåº«**: ChromaDB æä¾›é«˜æ•ˆçš„èªç¾©æœç´¢
- **å¤šæ ¼å¼æ”¯æ´**: PDFã€Wordã€æ–‡æœ¬ç­‰å¤šç¨®æ–‡æª”æ ¼å¼
- **å¢é‡æ›´æ–°**: æ”¯æ´å‹•æ…‹æ·»åŠ æ–°æ–‡æª”åˆ°ç¾æœ‰çŸ¥è­˜åº«

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æŠ€è¡“æ£§
```
å‰ç«¯: Next.js + TypeScript + Tailwind CSS
å¾Œç«¯: Python FastAPI + LangChain
å‘é‡æ•¸æ“šåº«: ChromaDB (æœ¬åœ°æŒä¹…åŒ–)
åµŒå…¥æ¨¡å‹: Google text-embedding-004
èªè¨€æ¨¡å‹: Google Gemini 2.0 Flash Exp
æ–‡æª”è™•ç†: PyPDFLoader, UnstructuredFileLoader
```

### RAG æ¶æ§‹çµ„ä»¶

#### 1. æ–‡æª”æ”å–ç®¡é“ (Document Ingestion Pipeline)
```python
class DocumentProcessor:
    def process_documents(self, file_paths: List[str]) -> List[Document]:
        # 1. æ–‡æª”åŠ è¼‰
        # 2. æ–‡æœ¬åˆ†å‰²
        # 3. å‘é‡åŒ–
        # 4. å­˜å„²åˆ°å‘é‡åº«
```

**è™•ç†æµç¨‹**:
```
æ–‡ä»¶ä¸Šå‚³ â†’ æ–‡æª”åŠ è¼‰ â†’ æ–‡æœ¬åˆ†å‰² â†’ å‘é‡åŒ– â†’ å­˜å„²åˆ° ChromaDB
```

#### 2. æª¢ç´¢ç³»çµ± (Retrieval System)
```python
class RetrievalSystem:
    def retrieve_relevant_docs(
        self, 
        query: str, 
        k: int = 5
    ) -> List[Document]:
        # èªç¾©æœç´¢å’Œç›¸é—œæ–‡æª”æª¢ç´¢
```

#### 3. ç”Ÿæˆç³»çµ± (Generation System)
```python
class QAChain:
    def generate_answer(
        self, 
        query: str, 
        context_docs: List[Document]
    ) -> AnswerWithSources:
        # åŸºæ–¼æª¢ç´¢åˆ°çš„æ–‡æª”ç”Ÿæˆç­”æ¡ˆ
```

## ğŸ“Š æ ¸å¿ƒæ¨¡çµ„è©³è§£

### 1. RAG æœå‹™ (`rag_service.py`)

#### ä¸»è¦é¡åˆ¥å’Œæ–¹æ³•
```python
class RAGService:
    def __init__(self):
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004"
        )
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.3
        )
        self.vector_store = Chroma(
            persist_directory="./vector_store",
            embedding_function=self.embeddings
        )
    
    async def process_documents(self, file_paths: List[str]) -> ProcessingResult
    async def query_documents(self, question: str) -> QAResult
    async def generate_summary(self, doc_ids: List[str]) -> SummaryResult
    async def generate_quiz(self, doc_ids: List[str]) -> QuizResult
```

#### æ–‡æª”è™•ç†æµç¨‹
```python
def process_documents(self, file_paths: List[str]):
    # 1. æ–‡æª”åŠ è¼‰
    documents = []
    for file_path in file_paths:
        if file_path.endswith('.pdf'):
            loader = PyPDFLoader(file_path)
        else:
            loader = UnstructuredFileLoader(file_path)
        documents.extend(loader.load())
    
    # 2. æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(documents)
    
    # 3. å‘é‡åŒ–ä¸¦å­˜å„²
    self.vector_store.add_documents(splits)
```

#### å•ç­”éˆæ§‹å»º
```python
def create_qa_chain(self):
    # å‰µå»ºæª¢ç´¢å™¨
    retriever = self.vector_store.as_retriever(
        search_kwargs={"k": 5}
    )
    
    # å®šç¾©æç¤ºè©æ¨¡æ¿
    prompt_template = """
    åŸºæ–¼ä»¥ä¸‹æ–‡æª”å…§å®¹å›ç­”å•é¡Œï¼Œä¸¦æä¾›å…·é«”çš„ä¾†æºå¼•ç”¨ï¼š
    
    æ–‡æª”å…§å®¹ï¼š
    {context}
    
    å•é¡Œï¼š{question}
    
    è«‹æä¾›è©³ç´°çš„ç­”æ¡ˆï¼Œä¸¦åœ¨ç­”æ¡ˆæœ«å°¾åˆ—å‡ºæ‰€æœ‰ç›¸é—œçš„ä¾†æºæ–‡æª”ã€‚
    """
    
    # å‰µå»º QA éˆ
    qa_chain = RetrievalQA.from_chain_type(
        llm=self.llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )
    
    return qa_chain
```

### 2. æ–‡æª”è™•ç†å™¨ (`document_processor.py`)

#### æ”¯æ´çš„æ–‡æª”æ ¼å¼
```python
SUPPORTED_FORMATS = {
    '.pdf': PyPDFLoader,
    '.docx': UnstructuredWordDocumentLoader,
    '.txt': TextLoader,
    '.md': UnstructuredMarkdownLoader,
    '.html': UnstructuredHTMLLoader
}
```

#### æ™ºèƒ½æ–‡æœ¬åˆ†å‰²
```python
class SmartTextSplitter:
    def __init__(self):
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        # æ ¹æ“šæ–‡æª”é¡å‹èª¿æ•´åˆ†å‰²ç­–ç•¥
        return self.splitter.split_documents(documents)
```

### 3. å‘é‡å­˜å„²ç®¡ç† (`vector_store_manager.py`)

#### ChromaDB é…ç½®
```python
class VectorStoreManager:
    def __init__(self, persist_directory: str = "./vector_store"):
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004"
        )
        self.vector_store = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings,
            collection_metadata={"hnsw:space": "cosine"}
        )
    
    def add_documents(self, documents: List[Document]) -> List[str]:
        # æ·»åŠ æ–‡æª”åˆ°å‘é‡åº«
        return self.vector_store.add_documents(documents)
    
    def similarity_search(self, query: str, k: int = 5) -> List[Document]:
        # åŸ·è¡Œèªç¾©æœç´¢
        return self.vector_store.similarity_search(query, k=k)
```

## ğŸ“Š æ•¸æ“šæ¨¡å‹

### æ ¸å¿ƒæ•¸æ“šçµæ§‹

#### Document (æ–‡æª”)
```python
class Document(BaseModel):
    page_content: str           # æ–‡æª”å…§å®¹
    metadata: Dict[str, Any]    # å…ƒæ•¸æ“šï¼ˆä¾†æºã€é ç¢¼ç­‰ï¼‰
```

#### QAResult (å•ç­”çµæœ)
```python
class QAResult(BaseModel):
    question: str               # ç”¨æˆ¶å•é¡Œ
    answer: str                # ç”Ÿæˆçš„ç­”æ¡ˆ
    source_documents: List[Document]  # ä¾†æºæ–‡æª”
    confidence_score: float     # ä¿¡å¿ƒåˆ†æ•¸
    processing_time: float      # è™•ç†æ™‚é–“
```

#### ProcessingResult (è™•ç†çµæœ)
```python
class ProcessingResult(BaseModel):
    session_id: str            # æœƒè©± ID
    processed_files: List[str] # å·²è™•ç†çš„æ–‡ä»¶
    total_chunks: int          # ç¸½æ–‡æœ¬å¡Šæ•¸
    processing_time: float     # è™•ç†æ™‚é–“
    status: str               # è™•ç†ç‹€æ…‹
```

#### QuizQuestion (æ¸¬é©—å•é¡Œ)
```python
class QuizQuestion(BaseModel):
    question: str              # å•é¡Œå…§å®¹
    options: List[str]         # é¸é …åˆ—è¡¨
    correct_answer: int        # æ­£ç¢ºç­”æ¡ˆç´¢å¼•
    explanation: str           # ç­”æ¡ˆè§£é‡‹
    source_document: str       # ä¾†æºæ–‡æª”
```

## ğŸ”„ RAG å·¥ä½œæµç¨‹

### å®Œæ•´çš„ RAG ç®¡é“
```mermaid
graph TD
    A[æ–‡æª”ä¸Šå‚³] --> B[æ–‡æª”åŠ è¼‰]
    B --> C[æ–‡æœ¬åˆ†å‰²]
    C --> D[å‘é‡åŒ–]
    D --> E[å­˜å„²åˆ° ChromaDB]
    E --> F[å»ºç«‹æª¢ç´¢å™¨]
    
    G[ç”¨æˆ¶æŸ¥è©¢] --> H[æŸ¥è©¢å‘é‡åŒ–]
    H --> I[èªç¾©æœç´¢]
    I --> J[æª¢ç´¢ç›¸é—œæ–‡æª”]
    J --> K[æ§‹å»ºæç¤ºè©]
    K --> L[LLM ç”Ÿæˆç­”æ¡ˆ]
    L --> M[è¿”å›çµæœèˆ‡ä¾†æº]
```

### æŸ¥è©¢è™•ç†æµç¨‹
```python
async def process_query(self, question: str, session_id: str) -> QAResult:
    # 1. æª¢ç´¢ç›¸é—œæ–‡æª”
    relevant_docs = self.vector_store.similarity_search(
        question, 
        k=5,
        filter={"session_id": session_id}
    )
    
    # 2. æ§‹å»ºä¸Šä¸‹æ–‡
    context = "\n\n".join([doc.page_content for doc in relevant_docs])
    
    # 3. ç”Ÿæˆç­”æ¡ˆ
    prompt = self.create_qa_prompt(question, context)
    response = await self.llm.agenerate([prompt])
    
    # 4. è¿”å›çµæœ
    return QAResult(
        question=question,
        answer=response.generations[0][0].text,
        source_documents=relevant_docs,
        confidence_score=self.calculate_confidence(relevant_docs),
        processing_time=time.time() - start_time
    )
```

## ğŸš€ API ç«¯é»

### ä¸»è¦ API è·¯ç”±

#### 1. ä¸Šå‚³æ–‡æª”
```http
POST /api/upload-documents
Content-Type: multipart/form-data

{
  "files": [<file1>, <file2>, ...],
  "session_name": "æˆ‘çš„çŸ¥è­˜åº«"
}
```

#### 2. æŸ¥è©¢æ–‡æª”
```http
POST /api/query
Content-Type: application/json

{
  "question": "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
  "session_id": "uuid",
  "max_results": 5
}
```

#### 3. ç”Ÿæˆæ‘˜è¦
```http
POST /api/generate-summary
Content-Type: application/json

{
  "session_id": "uuid",
  "doc_ids": ["doc1", "doc2"],
  "summary_type": "comprehensive"
}
```

#### 4. ç”Ÿæˆæ¸¬é©—
```http
POST /api/generate-quiz
Content-Type: application/json

{
  "session_id": "uuid",
  "num_questions": 10,
  "difficulty": "medium"
}
```

#### 5. ç²å–æœƒè©±åˆ—è¡¨
```http
GET /api/sessions
```

#### 6. åˆªé™¤æœƒè©±
```http
DELETE /api/session/{session_id}
```

## ğŸ”§ é…ç½®èˆ‡éƒ¨ç½²

### ç’°å¢ƒè®Šæ•¸
```env
# Google AI æœå‹™é…ç½®
GEMINI_API_KEY=your_gemini_api_key_here

# å‘é‡æ•¸æ“šåº«é…ç½®
VECTOR_STORE_PATH=./vector_store
CHROMA_PERSIST_DIRECTORY=./vector_store

# æ–‡æª”è™•ç†é…ç½®
MAX_FILE_SIZE=50MB
SUPPORTED_FORMATS=pdf,docx,txt,md,html
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# æª¢ç´¢é…ç½®
DEFAULT_K=5
MAX_K=20
SIMILARITY_THRESHOLD=0.7

# LLM é…ç½®
LLM_TEMPERATURE=0.3
MAX_TOKENS=2048
```

### éƒ¨ç½²éœ€æ±‚
- **Python**: 3.8+
- **Node.js**: 18+
- **ç£ç›¤ç©ºé–“**: è‡³å°‘ 50GB (ç”¨æ–¼å‘é‡æ•¸æ“šåº«å’Œæ–‡æª”å­˜å„²)
- **è¨˜æ†¶é«”**: å»ºè­° 16GB+ (å‘é‡è¨ˆç®—å’Œå¤§å‹æ–‡æª”è™•ç†)
- **CPU**: å¤šæ ¸å¿ƒè™•ç†å™¨ (ä¸¦è¡Œæ–‡æª”è™•ç†)

### æ€§èƒ½å„ªåŒ–
1. **æ‰¹é‡è™•ç†**: ä¸¦è¡Œè™•ç†å¤šå€‹æ–‡æª”
2. **å¢é‡ç´¢å¼•**: æ”¯æ´å‹•æ…‹æ·»åŠ æ–‡æª”è€Œä¸é‡å»ºæ•´å€‹ç´¢å¼•
3. **ç·©å­˜æ©Ÿåˆ¶**: å°å¸¸è¦‹æŸ¥è©¢çµæœé€²è¡Œç·©å­˜
4. **åˆ†ç‰‡å­˜å„²**: å¤§å‹çŸ¥è­˜åº«çš„åˆ†ç‰‡ç®¡ç†

## ğŸ“ˆ ç›£æ§èˆ‡åˆ†æ

### ç³»çµ±ç›£æ§æŒ‡æ¨™
- **æª¢ç´¢è³ªé‡**: ç›¸é—œæ–‡æª”çš„æº–ç¢ºç‡å’Œå¬å›ç‡
- **éŸ¿æ‡‰æ™‚é–“**: æŸ¥è©¢è™•ç†çš„å¹³å‡æ™‚é–“
- **å­˜å„²ä½¿ç”¨**: å‘é‡æ•¸æ“šåº«çš„å­˜å„²ç©ºé–“ä½¿ç”¨æƒ…æ³
- **API ä½¿ç”¨é‡**: Gemini API çš„èª¿ç”¨æ¬¡æ•¸å’Œæˆæœ¬

### å“è³ªè©•ä¼°
```python
class QualityMetrics:
    def calculate_retrieval_accuracy(self, queries: List[str]) -> float:
        # è¨ˆç®—æª¢ç´¢æº–ç¢ºç‡
        pass
    
    def measure_answer_relevance(self, qa_pairs: List[Tuple]) -> float:
        # è©•ä¼°ç­”æ¡ˆç›¸é—œæ€§
        pass
    
    def analyze_user_satisfaction(self, feedback: List[Feedback]) -> Report:
        # åˆ†æç”¨æˆ¶æ»¿æ„åº¦
        pass
```

## ğŸ§ª æ¸¬è©¦ç­–ç•¥

### åŠŸèƒ½æ¸¬è©¦
- æ–‡æª”ä¸Šå‚³å’Œè™•ç†æ¸¬è©¦
- å‘é‡åŒ–å’Œæª¢ç´¢æº–ç¢ºæ€§æ¸¬è©¦
- å•ç­”ç”Ÿæˆå“è³ªæ¸¬è©¦
- ä¾†æºå¼•ç”¨æº–ç¢ºæ€§é©—è­‰

### æ€§èƒ½æ¸¬è©¦
- å¤§å‹æ–‡æª”é›†åˆçš„è™•ç†æ€§èƒ½
- ä¸¦ç™¼æŸ¥è©¢çš„éŸ¿æ‡‰æ™‚é–“
- å‘é‡æ•¸æ“šåº«çš„æŸ¥è©¢æ•ˆç‡
- è¨˜æ†¶é«”ä½¿ç”¨é‡ç›£æ§

### æ•´åˆæ¸¬è©¦
- ç«¯åˆ°ç«¯çš„ RAG æµç¨‹æ¸¬è©¦
- å¤šæœƒè©±ä¸¦è¡Œè™•ç†æ¸¬è©¦
- API ç«¯é»çš„å®Œæ•´æ€§æ¸¬è©¦

## ğŸ”® æœªä¾†ç™¼å±•

### çŸ­æœŸç›®æ¨™
1. **å¤šæ¨¡æ…‹æ”¯æ´**: æ”¯æ´åœ–åƒå’Œè¡¨æ ¼å…§å®¹çš„ç†è§£
2. **é«˜ç´šæª¢ç´¢**: å¯¦ç¾æ··åˆæª¢ç´¢ï¼ˆé—œéµè© + èªç¾©ï¼‰
3. **å€‹æ€§åŒ–**: åŸºæ–¼ç”¨æˆ¶æ­·å²çš„å€‹æ€§åŒ–æª¢ç´¢

### é•·æœŸè¦åŠƒ
1. **å¯¦æ™‚æ›´æ–°**: æ”¯æ´æ–‡æª”çš„å¯¦æ™‚æ›´æ–°å’Œå¢é‡ç´¢å¼•
2. **çŸ¥è­˜åœ–è­œ**: æ§‹å»ºæ–‡æª”é–“çš„çŸ¥è­˜é—œè¯åœ–
3. **å¤šèªè¨€æ”¯æ´**: æ“´å±•åˆ°å…¶ä»–èªè¨€çš„æ–‡æª”è™•ç†

### ä¼æ¥­ç´šåŠŸèƒ½
1. **æ¬Šé™ç®¡ç†**: ç´°ç²’åº¦çš„æ–‡æª”è¨ªå•æ§åˆ¶
2. **å¯©è¨ˆæ—¥èªŒ**: å®Œæ•´çš„æ“ä½œè¨˜éŒ„å’Œè¿½è¹¤
3. **ç§æœ‰éƒ¨ç½²**: æ”¯æ´ä¼æ¥­å…§éƒ¨çš„ç§æœ‰åŒ–éƒ¨ç½²

---

**ç¶­è­·è€…**: AI Tools é–‹ç™¼åœ˜éšŠ  
**æœ€å¾Œæ›´æ–°**: 2024å¹´12æœˆ  
**ç‰ˆæœ¬**: v1.0.0