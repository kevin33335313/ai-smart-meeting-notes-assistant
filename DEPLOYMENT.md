# ğŸš€ éƒ¨ç½²æŒ‡å—

## æœ¬åœ°é–‹ç™¼ç’°å¢ƒ

### å¿«é€Ÿå•Ÿå‹•
```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/your-username/ai-smart-meeting-notes-assistant.git
cd ai-smart-meeting-notes-assistant

# 2. å®‰è£ä¾è³´
# å¾Œç«¯
cd backend
pip install -r requirements.txt
cp .env.example .env
# ç·¨è¼¯ .env æ·»åŠ  Gemini API Key

# å‰ç«¯
cd ../frontend
npm install

# 3. å•Ÿå‹•æœå‹™
# å¾Œç«¯ (æ–°çµ‚ç«¯)
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# å‰ç«¯ (æ–°çµ‚ç«¯)
cd frontend
npm run dev
```

### ç’°å¢ƒè®Šæ•¸é…ç½®
```env
# backend/.env
GEMINI_API_KEY=your_gemini_api_key_here
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
```

## ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

### Docker éƒ¨ç½² (æ¨è–¦)

#### 1. å»ºç«‹ Docker é…ç½®
```dockerfile
# Dockerfile.backend
FROM python:3.11-slim

WORKDIR /app
COPY backend/requirements.txt .
RUN pip install -r requirements.txt

COPY backend/ .
EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```dockerfile
# Dockerfile.frontend
FROM node:18-alpine

WORKDIR /app
COPY frontend/package*.json ./
RUN npm ci --only=production

COPY frontend/ .
RUN npm run build

EXPOSE 3000
CMD ["npm", "start"]
```

#### 2. Docker Compose
```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "8000:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      - ./uploads:/app/local_uploads

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - frontend
      - backend
```

### Vercel + Railway éƒ¨ç½²

#### å‰ç«¯ (Vercel)
1. é€£æ¥ GitHub å€‰åº«åˆ° Vercel
2. è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼š
   ```
   NEXT_PUBLIC_API_URL=https://your-backend-url.railway.app
   ```
3. è‡ªå‹•éƒ¨ç½²è¨­ç½®å®Œæˆ

#### å¾Œç«¯ (Railway)
1. é€£æ¥ GitHub å€‰åº«åˆ° Railway
2. è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼š
   ```
   GEMINI_API_KEY=your_api_key
   PORT=8000
   ```
3. æ·»åŠ  `railway.toml`ï¼š
   ```toml
   [build]
   builder = "NIXPACKS"
   buildCommand = "pip install -r backend/requirements.txt"

   [deploy]
   startCommand = "uvicorn backend.app.main:app --host 0.0.0.0 --port $PORT"
   ```

### AWS éƒ¨ç½²

#### ä½¿ç”¨ AWS App Runner
1. å»ºç«‹ `apprunner.yaml`ï¼š
   ```yaml
   version: 1.0
   runtime: python3
   build:
     commands:
       build:
         - pip install -r backend/requirements.txt
   run:
     runtime-version: 3.11
     command: uvicorn backend.app.main:app --host 0.0.0.0 --port 8000
     network:
       port: 8000
       env: PORT
   ```

#### ä½¿ç”¨ ECS + Fargate
1. å»ºç«‹ ECR å€‰åº«
2. æ¨é€ Docker æ˜ åƒ
3. å»ºç«‹ ECS ä»»å‹™å®šç¾©
4. é…ç½® Application Load Balancer

## ç’°å¢ƒé…ç½®

### ç”Ÿç”¢ç’°å¢ƒè®Šæ•¸
```env
# å¾Œç«¯
GEMINI_API_KEY=prod_api_key
ENVIRONMENT=production
LOG_LEVEL=INFO
CORS_ORIGINS=https://yourdomain.com

# å‰ç«¯
NEXT_PUBLIC_API_URL=https://api.yourdomain.com
NEXT_PUBLIC_ENVIRONMENT=production
```

### å®‰å…¨é…ç½®
- ä½¿ç”¨ HTTPS
- è¨­ç½® CORS ç™½åå–®
- é…ç½® API é€Ÿç‡é™åˆ¶
- å•Ÿç”¨è«‹æ±‚æ—¥èªŒè¨˜éŒ„

## ç›£æ§å’Œæ—¥èªŒ

### æ‡‰ç”¨ç›£æ§
```python
# backend/app/middleware/monitoring.py
import time
from fastapi import Request
import logging

logger = logging.getLogger(__name__)

async def log_requests(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    logger.info(
        f"{request.method} {request.url} - "
        f"Status: {response.status_code} - "
        f"Time: {process_time:.4f}s"
    )
    return response
```

### å¥åº·æª¢æŸ¥ç«¯é»
```python
# backend/app/main.py
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow(),
        "version": "1.0.0"
    }
```

## å‚™ä»½å’Œæ¢å¾©

### æ•¸æ“šå‚™ä»½
```bash
# å‚™ä»½ä¸Šå‚³æ–‡ä»¶
tar -czf uploads_backup_$(date +%Y%m%d).tar.gz backend/local_uploads/

# å‚™ä»½é…ç½®
cp backend/.env config_backup_$(date +%Y%m%d).env
```

### è‡ªå‹•å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# backup.sh
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups"

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR

# å‚™ä»½æ–‡ä»¶
tar -czf $BACKUP_DIR/uploads_$DATE.tar.gz backend/local_uploads/

# æ¸…ç†èˆŠå‚™ä»½ (ä¿ç•™7å¤©)
find $BACKUP_DIR -name "uploads_*.tar.gz" -mtime +7 -delete

echo "Backup completed: uploads_$DATE.tar.gz"
```

## æ€§èƒ½å„ªåŒ–

### å‰ç«¯å„ªåŒ–
- å•Ÿç”¨ Next.js åœ–ç‰‡å„ªåŒ–
- ä½¿ç”¨ CDN åˆ†ç™¼éœæ…‹è³‡æº
- å¯¦æ–½ä»£ç¢¼åˆ†å‰²å’Œæ‡¶åŠ è¼‰

### å¾Œç«¯å„ªåŒ–
- ä½¿ç”¨ Redis å¿«å–
- å¯¦æ–½é€£æ¥æ± 
- é…ç½® Gunicorn å¤šé€²ç¨‹

```python
# gunicorn.conf.py
bind = "0.0.0.0:8000"
workers = 4
worker_class = "uvicorn.workers.UvicornWorker"
max_requests = 1000
max_requests_jitter = 100
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ
1. **API é€£æ¥å¤±æ•—**
   - æª¢æŸ¥ CORS è¨­ç½®
   - é©—è­‰ API URL é…ç½®

2. **Gemini API éŒ¯èª¤**
   - ç¢ºèª API Key æœ‰æ•ˆ
   - æª¢æŸ¥é…é¡é™åˆ¶

3. **æ–‡ä»¶ä¸Šå‚³å¤±æ•—**
   - æª¢æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
   - é©—è­‰å­˜å„²æ¬Šé™

### æ—¥èªŒæŸ¥çœ‹
```bash
# Docker æ—¥èªŒ
docker-compose logs -f backend
docker-compose logs -f frontend

# ç³»çµ±æ—¥èªŒ
tail -f /var/log/app.log
```

---

é¸æ“‡é©åˆä½ éœ€æ±‚çš„éƒ¨ç½²æ–¹æ¡ˆï¼Œä¸¦æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´é…ç½®ã€‚